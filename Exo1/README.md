# ğŸ“˜ README --- Flight Data 2024 Â· CSV vs Parquet Benchmark

## ğŸš€ Objectif du projet

Ce projet permet de :

-   TÃ©lÃ©charger automatiquement le dataset **Flight Data 2024** depuis
    Kaggle\
-   Extraire le fichier CSV et supprimer les fichiers superflus\
-   Convertir le CSV en deux formats Parquet :
    -   **Parquet non compressÃ©**
    -   **Parquet compressÃ© (brotli)**
-   Comparer :
    -   â± Temps de lecture\
    -   â± Temps d'Ã©criture\
    -   ğŸ’¾ Tailles des fichiers\
    -   â± Lecture de colonnes sÃ©lectionnÃ©es (CSV vs Parquet)

Le script fournit un tableau comparatif propre pour toutes les Ã©tapes.

------------------------------------------------------------------------

## ğŸ“‚ Structure du projet

    project/
    â”‚â”€â”€ main.py
    â”‚â”€â”€ requirements.txt
    â”‚â”€â”€ README.md
    â”‚â”€â”€ flight_data_2024.zip (auto-tÃ©lÃ©chargÃ© si absent)
    â””â”€â”€ data/
        â”‚â”€â”€ flight_data_2024.csv
        â”‚â”€â”€ flight_data_2024.parquet
        â””â”€â”€ flight_data_2024_compressed.parquet

------------------------------------------------------------------------

## ğŸ”§ Installation

### 1. Cloner le dÃ©pÃ´t

``` bash
git clone <url_du_repo>
cd <repo>
```

### 2. CrÃ©er un environnement virtuel

``` bash
python -m venv venv
```

### 3. Activer l'environnement

**Windows**

``` bash
venv\Scripts\activate
```

**Linux/MacOS**

``` bash
source venv/bin/activate
```

### 4. Installer les dÃ©pendances

``` bash
pip install -r requirements.txt
```

------------------------------------------------------------------------

## ğŸ“¦ Requirements (requirements.txt)

    pandas
    pyarrow
    fastparquet
    requests
    zipfile
    tqdm

------------------------------------------------------------------------

## ğŸ›  ExÃ©cution du script

``` bash
python main.py
```

------------------------------------------------------------------------

## ğŸ“Š FonctionnalitÃ©s dÃ©taillÃ©es

### âœ” TÃ©lÃ©chargement automatique depuis Kaggle

### âœ” Extraction + nettoyage

### âœ” Benchmarks CSV vs Parquet

------------------------------------------------------------------------

## ğŸ§ª Colonnes analysÃ©es

    op_carrier_fl_num
    origin_city_name

------------------------------------------------------------------------

## ğŸ“˜ Variables importantes

``` python
PATHS = {
    "zip": "flight_data_2024.zip",
    "data_folder": "data",
    "csv": "data/flight_data_2024.csv",
    "parquet_raw": "data/flight_data_2024.parquet",
    "parquet_compressed": "data/flight_data_2024_compressed.parquet"
}
```

------------------------------------------------------------------------

## ğŸ” Pourquoi ce projet est utile ?

Parce que Parquet :

-   compresse mieux\
-   se lit beaucoup plus vite\
-   est optimisÃ© pour les colonnes\
-   est standard dans les pipelines modernes (Spark, Dask, Snowflake,
    BigQuery)

------------------------------------------------------------------------

## ğŸ“„ Licence

Libre de rÃ©utilisation et de modification.
